---
title: PyTorch保存加载模型
author: 赵旭山
tags: PyTorch
---

#### 1. 简介

断点续算，是一个永恒的话题，也是老生常谈的问题。最近一次，是我的领导兼师长带着批评意味跟我谈论我们的学科专业软件VASP，从他的言谈话语中，我虽不满他侵犯我的专业领域，但也隐约感觉到了一些新的讯息，适应当前可依赖的资源，而不是环境可以去适应你。对于此，我非常感激！

于此，正在学习PyTorch的点点滴滴，自然而然的也乍现了这个问题。闲言少叙，继续记录我的学习笔记：PyTorch的保存加载模型，只为断点续算！

主要参考：[https://www.jianshu.com/p/4905bf8e06e5](https://www.jianshu.com/p/4905bf8e06e5)

#### 2. PyTorch相关命令

`torch.save`

`torch.load`

`torch.nn.Module.load_state_dict`

前两个自然是成对的，我最初的理解就是全部保存和加载，实际使用中并不是那么回事儿，直接`load`会报错，要求我先定义`model`的`class`，看样子模型结构应该是没有的。

先照搬过来：

```
"1.torch.save：将序列化的对象保存到disk。这个函数使用Python的pickle实用程序进行序列化。使用这个函数可以保存各种对象的模型、张量和字典。"

"2.torch.load：使用pickle unpickle工具将pickle的对象文件反序列化为内存。"

"3.torch.nn.Module.load_state_dict:使用反序列化状态字典加载model’s参数字典。"
```

至于啥是序列化，反正我现在是没有完全理解，就是一个序列吧，按`nn.Sequential`理解的。

就一个模型而言，须保存的，结构、参数、权重、误差，是最必要的。

#### 2. 先说“`state_dict`”

感觉上，这个应该不如`torch.save`，没`torch.save`保存的信息全。



#### References

[PyTorch之保存加载模型](https://www.jianshu.com/p/4905bf8e06e5)