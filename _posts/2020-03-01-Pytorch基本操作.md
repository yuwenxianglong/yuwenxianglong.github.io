---
title: Pytorch基本操作
author: 赵旭山
tags: Pytorch
---

#### 1. Pytorch基本操作概要

搜索网页学习Pytorch中看到一张结构清晰的思维导图，作者总结得很清晰，引用过来学习学习。如下：

Figure source: [https://zhuanlan.zhihu.com/p/36233589](https://zhuanlan.zhihu.com/p/36233589)

![](/assets/images/pytorchflowchart202002272158.jpg)

#### 2. Tensor属性

```python
x = torch.rand(5, 3)
x.dtype
x.device
x.layout
x.stride()
```

> torch.float32
>
> device(type='cpu')
>
> torch.strided
>
> (3, 1)

dtype就是数据的类型，Pytorch共有八种数据类型：

| Data type                | dtype                         | dtype                |
| ------------------------ | ----------------------------- | -------------------- |
| 32-bit floating point    | torch.float32 or torch.float  | torch.*.FloatTensor  |
| 64-bit floating point    | torch.float64 or torch.double | torch.*.DoubleTensor |
| 16-bit floating point    | torch.float16 or torch.half   | torch.*.HalfTensor   |
| 8-bit integer (unsigned) | torch.uint8                   | torch.*.ByteTensor   |
| 8-bit integer (signed)   | torch.int8                    | torch.*.CharTensor   |
| 16-bit integer (signed)  | torch.int16 or torch.short    | torch.*.ShortTensor  |
| 32-bit integer (signed)  | torch.int32 or torch.int      | torch.*.IntTensor    |
| 64-bit integer (signed)  | torch.int64 or torch.long     | torch.*.LongTensor   |

layout是数据在内存中是怎么存的，分为稀疏张量和致密张量，常用的为致密张量（`torch.strided`）。

笔者**朴素的理解**就是定义的变量在内存中咋存储的，对二维矩阵而言，用了多少列，行则被展平存成一行。`x.t()`等同于矩阵转置，没存，只把两个数据交换了一下输出。

```python
In [7]: x.stride()                                              
Out[7]: (3, 1)

In [8]: x                                                       
Out[8]: 
tensor([[0.6031, 0.0937, 0.3282],
        [0.2758, 0.8520, 0.1412],
        [0.9676, 0.9618, 0.5699],
        [0.1657, 0.2150, 0.9051],
        [0.7828, 0.9131, 0.4832]])

In [9]: x.stride()                                              
Out[9]: (3, 1)

In [10]: x.t()                                                  
Out[10]: 
tensor([[0.6031, 0.2758, 0.9676, 0.1657, 0.7828],
        [0.0937, 0.8520, 0.9618, 0.2150, 0.9131],
        [0.3282, 0.1412, 0.5699, 0.9051, 0.4832]])

In [11]: x.t().stride()                                         
Out[11]: (1, 3)
```

对于三维张量，后两维相乘是第一个数，最后一维是第二个数，最后一个数为1。t()函数只适用于2维及以下的张量，三维及以上不适用。

```python
In [30]: x =torch.rand(3, 8, 5)                                 

In [31]: x.size()                                               
Out[31]: torch.Size([3, 8, 5])

In [32]: x.stride()                                             
Out[32]: (40, 5, 1)

In [33]: xx = torch.rand(6, 3, 7)                               

In [34]: xx.size()                                              
Out[34]: torch.Size([6, 3, 7])

In [35]: xx.stride()                                            
Out[35]: (21, 7, 1)
  
In [36]: xx.t()                                                 
----------------------------------------------------------------
RuntimeError                   Traceback (most recent call last)
<ipython-input-36-0b88b5bf88e4> in <module>
----> 1 xx.t()

RuntimeError: t() expects a tensor with <= 2 dimensions, but self is 3D

```

#### 3. 创建Tensor

##### 3.1 直接创建

**torch.tensor()**

```python
In [2]: cell = torch.tensor([[6.50, 0, 0], [0, 6.50, 0], [0, 0, 
   ...: 6.50]])                                                 

In [3]: cell                                                    
Out[3]: 
tensor([[6.5000, 0.0000, 0.0000],
        [0.0000, 6.5000, 0.0000],
        [0.0000, 0.0000, 6.5000]])
```

##### 3.2 创建类型相似但size不同的tensor

**.new()**：`inputs.new`&`torch.Tensor.new`

参考: [https://www.jb51.net/article/180679.htm](https://www.jb51.net/article/180679.htm)

创建一个新的Tensor，该Tensor的**type**和**device**都和原有Tensor一致，且无内容。

```python
In [2]: inputs = torch.rand(5, 3)                               

In [3]: inputs                                                  
Out[3]: 
tensor([[0.7991, 0.8743, 0.1387],
        [0.9594, 0.9258, 0.3077],
        [0.3318, 0.3850, 0.5850],
        [0.9942, 0.3455, 0.2891],
        [0.4658, 0.9288, 0.7334]])

In [4]: new_inputs1 = inputs.new()                               

In [5]: new_inputs1                                              
Out[5]: tensor([])

In [6]: new_inputs2 = torch.Tensor.new(inputs)                  

In [7]: new_inputs2                                             
Out[7]: tensor([])

In [8]: new_inputs3 = inputs.new(inputs.size())                 

In [9]: new_inputs3                                            
Out[9]: 
tensor([[0.0000e+00, 1.4013e-45, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00],
        [1.1704e-41, 0.0000e+00, 2.2369e+08],
        [0.0000e+00, 0.0000e+00, 0.0000e+00]])

In [10]: inputs.dtype, new_inputs1.dtype, new_inputs2.dtype, new_inputs3.dtype                                          
Out[10]: (torch.float32, torch.float32, torch.float32, torch.float32)

In [11]: inputs.device, new_inputs.device, new_inputs2.device, new_inputs3.device                                      
Out[11]: 
(device(type='cpu'), device(type='cpu'), device(type='cpu'), device(type='cpu'))
```

实际应用：**添加噪声**

可以对Tensor**添加噪声**，添加如下代码即可实现：

```python
In [17]: noise = inputs.new(inputs.size()).normal_(0, 0.01)    

In [18]: noise                                                 
Out[18]: 
tensor([[-0.0021, -0.0025,  0.0182],
        [-0.0016,  0.0106, -0.0039],
        [ 0.0023,  0.0112,  0.0024],
        [ 0.0109,  0.0007,  0.0089],
        [ 0.0177,  0.0003, -0.0026]])
```

类似的有：`.new_ones`、`.new_zeros`。

##### 3.3 从numpy生成

**torch.from_numpy()**

参考：https://www.jb51.net/article/144520.htm

```python
In [3]: np_data = np.arange(6).reshape((2, 3))                  

In [4]: np_data                                                 
Out[4]: 
array([[0, 1, 2],
       [3, 4, 5]])

# numpy 转为 pytorch格式

In [5]: torch_data = torch.from_numpy(np_data)                  

In [6]: torch_data                                              
Out[6]: 
tensor([[0, 1, 2],
        [3, 4, 5]])

# torch 转为numpy

In [7]: tensor2array = torch_data.numpy()                       

In [8]: tensor2array                                            
Out[8]: 
array([[0, 1, 2],
       [3, 4, 5]])
```

矩阵转换为Tensor：

```python
# 转为32位浮点数，torch接受的都是Tensor的形式
In [1]: data = [[1, 2], [3, 4]]                                 

In [2]: data                                                    
Out[2]: [[1, 2], [3, 4]]

In [3]: tensor = torch.FloatTensor(data)                        

In [4]: tensor                                                  
Out[4]: 
tensor([[1., 2.],
        [3., 4.]])
```

##### 3.4 创建特定Tensor

###### 3.4.1 根据矩阵要求

**torch.eye()**

参考：https://www.cnblogs.com/btschang/p/10300727.html

对角线位置全1，其它位置全为0的二维矩阵。

```
In [7]: torch.eye(6)                                            
Out[7]: 
tensor([[1., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0.],
        [0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 1.]])
```

**torch.empty()**

参考：https://www.cnblogs.com/gato-chat/p/9064974.html

empty方法创建的矩阵不是空矩阵，而是未初始化的矩阵，所以里面的值不一定是0。

```python
In [2]: x = torch.empty(5, 3)                                   

In [3]: x                                                       
Out[3]: 
tensor([[0.0000e+00, -0.0000e+00, 0.0000e+00],
        [-0.0000e+00, 1.8361e+25, 1.4603e-19],
        [1.6795e+08, 4.7423e+30, 4.7393e+30],
        [9.5461e-01, 4.4377e+27, 1.7975e+19],
        [4.6894e+27, 7.9463e+08, 3.2604e-12]])
```

**torch.empty_like()**

`torch.empty_like(input)`返回和input的tensor一样size的empty张量。

```python
In [2]: x = torch.rand(5, 3)                                    

In [3]: x                                                       
Out[3]: 
tensor([[0.9643, 0.6685, 0.7706],
        [0.4562, 0.1438, 0.7719],
        [0.3813, 0.3628, 0.9026],
        [0.3653, 0.0948, 0.2917],
        [0.6953, 0.5089, 0.1560]])

In [4]: xx = torch.empty_like(x)                                

In [5]: xx                                                      
Out[5]: 
tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 1.8028e+28, 3.4740e-12],
        [1.4583e-19, 7.3470e+28, 6.1425e+28],
        [7.1441e+31, 6.9987e+22, 7.8675e+34],
        [4.7418e+30, 5.9663e-02, 7.0374e+22]])
```

###### 3.4.2 根据数值要求

**torch.zeros()**

参考：https://www.cnblogs.com/gato-chat/p/9064974.html

生成0矩阵，detype参数指定了生成的数据的类型。

```python
In [9]: x = torch.zeros(5, 3, dtype=torch.long)                 

In [10]: x                                                      
Out[10]: 
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
```

**torch.zeros_like()**

`torch.zeros_like(input)`返回跟input的tensor一个size的全零tensor。

```python
In [6]: xx = torch.zeros_like(x)                                

In [7]: xx                                                      
Out[7]: 
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
```

以下的`*_like`方法与以上相同，不再一一赘述。

**torch.ones()**

返回全1矩阵。

```python
In [2]: x = torch.ones(5, 3)                                    

In [3]: x                                                       
Out[3]: 
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
```

**torch.full()**

`torch.full(size, fill_value)`生成一个用fill_value填充的特定size张量。

```python
In [6]: x = torch.full((5, 3), 2.71828)                         

In [7]: x                                                       
Out[7]: 
tensor([[2.7183, 2.7183, 2.7183],
        [2.7183, 2.7183, 2.7183],
        [2.7183, 2.7183, 2.7183],
        [2.7183, 2.7183, 2.7183],
        [2.7183, 2.7183, 2.7183]])
```

**torch.arange()** & **torch.range()**

参考：https://blog.csdn.net/m0_37586991/article/details/88830026

```python
In [2]: x = torch.range(1, 6)                                   
/usr/local/Caskroom/miniconda/base/bin/ipython:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].
  #!/usr/local/Caskroom/miniconda/base/bin/python

In [3]: x                                                       
Out[3]: tensor([1., 2., 3., 4., 5., 6.])

In [4]: y = torch.arange(1, 6)                                  

In [5]: y                                                       
Out[5]: tensor([1, 2, 3, 4, 5])

In [6]: x.dtype, y.dtype                                        
Out[6]: (torch.float32, torch.int64)
```

(1) `torch.range(start=1, end=6)`的结果是会包含`end`的，而`torch.arange(start=1, end=6)`的结果并不包括`end`；

(2) 两者创建的`tensor`的类型也不一样。

**torch.linspace()**

参考：https://blog.csdn.net/york1996/article/details/81671128

`torch.linspace(start, end, steps)`返回一个一维的tensor，这个张量包含了从start到end，分成steps个段得到的向量。输出张量的长度由steps决定。

```python
In [2]: torch.linspace(3, 10, 5)                                
Out[2]: tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])

In [3]: torch.linspace(-10, 10, steps=6)                        
Out[3]: tensor([-10.,  -6.,  -2.,   2.,   6.,  10.])
```

**torch.logspace()**

`torch.logspace(start, end, steps)`返回一个一维的tensor，这个张量包含了从<img src="http://latex.codecogs.com/gif.latex?\10^{start}" />  到<img src="http://latex.codecogs.com/gif.latex?\10^{end}" />，分成steps个段得到的向量。输出张量的长度由steps决定。

```python
In [4]: torch.logspace(1, 5, 4)                                 
Out[4]: tensor([1.0000e+01, 2.1544e+02, 4.6416e+03, 1.0000e+05])

In [5]: torch.logspace(1, 5, 5)                                 
Out[5]: tensor([1.0000e+01, 1.0000e+02, 1.0000e+03, 1.0000e+04, 1.0000e+05])
```

##### 3.5 随机采样生成

**torch.normal()**

参考：[https://blog.csdn.net/sxs11/article/details/81775715](https://blog.csdn.net/sxs11/article/details/81775715)

`torch.normal(mean, std)`返回一个张量，包含从给定参数means、std的离散正态分布中抽取随机数。

> mean — 均值
>
> std — 标准差

```python
In [11]: torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))                                                    
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-11-4540d51055de> in <module>
----> 1 torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))

TypeError: normal() received an invalid combination of arguments - got (std=Tensor, means=Tensor, ), but expected one of:
 * (Tensor mean, Tensor std, torch.Generator generator, Tensor out)
 * (Tensor mean, float std, torch.Generator generator, Tensor out)
 * (float mean, Tensor std, torch.Generator generator, Tensor out)
 * (float mean, float std, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)


In [12]: torch.normal(mean=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))                                                     
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-12-a4a4388458ef> in <module>
----> 1 torch.normal(mean=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))

RuntimeError: "norma_cpu" not implemented for 'Long'

In [13]: torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))                                                   
Out[13]: 
tensor([ 1.8979,  1.5922,  3.0055,  3.7566,  4.8068,  6.4627,  7.1539,  7.4512,
         9.1401, 10.0355])
```

简单分析`In [11]`、`In [12]`两种错误：

**In [11]**: [参考网页](https://blog.csdn.net/sxs11/article/details/81775715)中输入参数`means=...`不工作，改成`mean=...`就可以了，另外此处给出了`normal`函数的几种输入组合：

>  * (Tensor mean, Tensor std, torch.Generator generator, Tensor out)
>  * (Tensor mean, float std, torch.Generator generator, Tensor out)
>  * (float mean, Tensor std, torch.Generator generator, Tensor out)
>  * (float mean, float std, tuple of ints size, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

**In [12]**: 根据上述输入组合，`std`和`mean`只接受`float`和`Tensor`两种dtype，所以`In [12]`中`mean=torch.arange(1, 11)`不工作，改成`mean=torch.arange(1., 11.)`即可。

其中：

```python
In [13]: torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))                                                   
Out[13]: 
tensor([ 1.8979,  1.5922,  3.0055,  3.7566,  4.8068,  6.4627,  7.1539,  7.4512,
         9.1401, 10.0355])
```

根据`mean`和`std`生成的张量含义如下：

```python
 1.8979 #是从均值为1，标准差为1的正态分布中随机生成的
 1.5922 #是从均值为2，标准差为0.9的正态分布中随机生成的
 3.0055 #是从均值为3，标准差为0.8的正态分布中随机生成的
 3.7566 #是从均值为4，标准差为0.7的正态分布中随机生成的
 4.8068 #是从均值为5，标准差为0.6的正态分布中随机生成的
 6.4627 #是从均值为6，标准差为0.5的正态分布中随机生成的
 7.1539 #是从均值为7，标准差为0.4的正态分布中随机生成的
 7.4512 #是从均值为8，标准差为0.3的正态分布中随机生成的
 9.1401 #是从均值为9，标准差为0.2的正态分布中随机生成的
10.0355 #是从均值为10，标准差为0.1的正态分布中随机生成的
```

<u>6.4627（均值为6，标准差为0.5）和7.4512（是从均值为8，标准差为0.3）</u>两个值有所偏差。

**torch.rand()** & **torch.randn()**

torch.randn()和torch.rand()有什么区别

参考：[https://blog.csdn.net/wangwangstone/article/details/89815661](https://blog.csdn.net/wangwangstone/article/details/89815661)

torch.rand和torch.randn有什么区别？ y = torch.rand(5,3) y=torch.randn(5,3)

一个均匀分布，一个是标准正态分布。

**均匀分布**

`torch.rand(*size)`返回一个张量，包含了从区间[0,1)的均匀分布中抽取的一组随机数。张量的形状由参数size定义。

```python
In [21]: torch.rand(size=(3, 2))                                 
Out[21]: 
tensor([[0.2218, 0.1115],
        [0.7232, 0.4805],
        [0.7677, 0.1653]])

In [22]: torch.rand(5, 3)                                       
Out[22]: 
tensor([[0.4548, 0.8788, 0.6698],
        [0.6992, 0.2677, 0.1843],
        [0.8135, 0.6389, 0.9419],
        [0.8074, 0.5690, 0.4269],
        [0.7801, 0.3185, 0.3531]])
```

**标准正态分布**

`torch.randn(*size)`返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）。

```python
In [23]: torch.randn(size=(4, 2))                               
Out[23]: 
tensor([[-2.5096,  0.3663],
        [ 0.8938,  0.3082],
        [ 0.0469,  0.3610],
        [-0.6472, -0.0929]])

In [24]: torch.randn(4, 2)                                      
Out[24]: 
tensor([[ 0.1326,  1.4875],
        [-0.3001,  0.0889],
        [ 0.5647,  0.5865],
        [ 0.6648,  0.7136]])
```

>`其他`：
>
>**离散正态分布**
>
>`torch.normal(mean, std)`，用法见前述。
>
>**线性间距向量**
>
>`torch.linspace(start, end, steps=100)`，用法见前述。



References

* [pytorch入坑一: Tensor及其基本操作](https://zhuanlan.zhihu.com/p/36233589)
* [Pytorch中.new()的作用详解](https://www.jb51.net/article/180679.htm)
* [浅谈pytorch和Numpy的区别以及相互转换方法](https://www.jb51.net/article/144520.htm)
* [**torch.eye**](https://www.cnblogs.com/btschang/p/10300727.html)
* [PyTorch的学习笔记](https://www.cnblogs.com/gato-chat/p/9064974.html)
* [pytorch.range() 和 pytorch.arange() 的区别](https://blog.csdn.net/m0_37586991/article/details/88830026)
* [PyTorch中linspace的详细用法](https://blog.csdn.net/york1996/article/details/81671128)
* [torch.normal()](https://blog.csdn.net/sxs11/article/details/81775715)
* [torch.randn和torch.rand有什么区别](https://blog.csdn.net/wangwangstone/article/details/89815661)

