---
title: æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç®—æ³•
author: èµµæ—­å±±
tags: PyTorch
---

#### 1. æ¦‚è§ˆ

å¯¹æœºå™¨å­¦ä¹ çš„ç®—æ³•ä¸€çŸ¥åŠè§£ï¼Œæœ¬æ–‡æ˜¯ä¸ªäººæ€»ç»“æ•´ç†å¤‡å¿˜ã€‚å¼•ç”¨ä¸¤å¼ [æ–‡çŒ®](https://arxiv.org/pdf/1609.04747.pdf)ä¸­çš„åŠ¨æ€å›¾ï¼š

![](/assets/images/optimizationAlgorithmOfDNN.gif)

![](/assets/images/lossSurfaceOfDNN.gif)

> "æœ€ä¼˜åŒ–é—®é¢˜æ˜¯è®¡ç®—æ•°å­¦ä¸­æœ€ä¸ºé‡è¦çš„ç ”ç©¶æ–¹å‘ä¹‹ä¸€ã€‚è€Œåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©ä¹Ÿæ˜¯ä¸€ä¸ªæ¨¡å‹çš„é‡ä¸­ä¹‹é‡ã€‚å³ä½¿åœ¨æ•°æ®é›†å’Œæ¨¡å‹æ¶æ„å®Œå…¨ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œé‡‡ç”¨ä¸åŒçš„ä¼˜åŒ–ç®—æ³•ï¼Œä¹Ÿå¾ˆå¯èƒ½å¯¼è‡´æˆªç„¶ä¸åŒçš„è®­ç»ƒæ•ˆæœã€‚
>
> æ¢¯åº¦ä¸‹é™æ˜¯ç›®å‰ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨æœ€ä¸ºå¹¿æ³›çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ã€‚ä¸ºäº†å¼¥è¡¥æœ´ç´ æ¢¯åº¦ä¸‹é™çš„ç§ç§ç¼ºé™·ï¼Œç ”ç©¶è€…ä»¬å‘æ˜äº†ä¸€ç³»åˆ—å˜ç§ç®—æ³•ï¼Œä»æœ€åˆçš„ SGD (éšæœºæ¢¯åº¦ä¸‹é™) é€æ­¥æ¼”è¿›åˆ° NAdamã€‚ç„¶è€Œï¼Œè®¸å¤šå­¦æœ¯ç•Œæœ€ä¸ºå‰æ²¿çš„æ–‡ç« ä¸­ï¼Œéƒ½å¹¶æ²¡æœ‰ä¸€å‘³ä½¿ç”¨ Adam/NAdam  ç­‰å…¬è®¤â€œå¥½ç”¨â€çš„è‡ªé€‚åº”ç®—æ³•ï¼Œå¾ˆå¤šç”šè‡³è¿˜é€‰æ‹©äº†æœ€ä¸ºåˆçº§çš„ SGD æˆ–è€… SGD with Momentum ç­‰ã€‚"

#### 2. æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼ŒGDï¼‰

æ¢¯åº¦ä¸‹é™ç®—æ³•é€šè¿‡æ²¿æ¢¯åº¦çš„ç›¸åæ–¹å‘æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œå­¦ä¹ ç‡ğœ‚ä¸ºæ¯ä¸€æ—¶åˆ»çš„æ›´æ–°æ­¥é•¿ã€‚[æ­¤æ–‡](https://zhuanlan.zhihu.com/p/32626442)ç»™å‡ºäº†æ¢¯åº¦ä¸‹é™çš„æµç¨‹ï¼š

ï¼ˆ1ï¼‰ è®¡ç®—ç›®æ ‡å‡½æ•°å…³äºå‚æ•°çš„æ¢¯åº¦

$$ g_t = \nabla_\theta J(\theta) $$

ï¼ˆ2ï¼‰ æ ¹æ®**å†å²**æ¢¯åº¦è®¡ç®—ä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡

$$ m_t = \phi(g_1, g_2, ..., g_t) $$

$$ \upsilon_t = \psi(g_1, g_2, ..., g_t) $$

ï¼ˆ3ï¼‰ æ›´æ–°æ¨¡å‹å‚æ•°

$$ \theta_{t+1} = \theta_t - \frac{1}{\sqrt{\upsilon_t + \epsilon}}m_t $$

å…¶ä¸­ï¼Œ$ \epsilon $ä¸ºå¹³æ»‘é¡¹ï¼Œé˜²æ­¢åˆ†æ¯ä¸ºé›¶ï¼Œé€šå¸¸å–$ 10^{-8} $ã€‚

#### 2. Gradient Descentå˜ç§ç®—æ³•

æ¢¯åº¦ä¸‹é™æœ€å¸¸è§çš„ä¸‰ç§å˜å½¢ï¼šBatch Gradient Descentï¼ˆBGDï¼‰ã€Stochastic Gradient Descentï¼ˆSGDï¼‰ã€Mini-Batch Gradient Descentï¼ˆMBGDï¼‰ï¼Œè¿™ä¸‰ç§å½¢å¼çš„åŒºåˆ«å°±æ˜¯ç”¨å¤šå°‘æ•°æ®æ¥è®¡ç®—ç›®æ ‡å‡½æ•°çš„æ¢¯åº¦ã€‚[å‚é˜…æ­¤æ–‡](https://www.cnblogs.com/guoyaohua/p/8542554.html)ã€‚

##### 2.1 éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descentï¼ŒSGDï¼‰









#### References

* [ä» SGD åˆ° Adam â€”â€” æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç®—æ³•æ¦‚è§ˆ(ä¸€)](https://zhuanlan.zhihu.com/p/32626442)
* [æ·±åº¦å­¦ä¹ æœ€å…¨ä¼˜åŒ–æ–¹æ³•æ€»ç»“æ¯”è¾ƒï¼ˆSGDï¼ŒAdagradï¼ŒAdadeltaï¼ŒAdamï¼ŒAdamaxï¼ŒNadamï¼‰](https://zhuanlan.zhihu.com/p/22252270)
* [æ·±åº¦å­¦ä¹ â€”â€”ä¼˜åŒ–å™¨ç®—æ³•Optimizerè¯¦è§£ï¼ˆBGDã€SGDã€MBGDã€Momentumã€NAGã€Adagradã€Adadeltaã€RMSpropã€Adamï¼‰](https://www.cnblogs.com/guoyaohua/p/8542554.html)
* [An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)
* [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/) 
* [Pytorchä¸­å¸¸ç”¨çš„å››ç§ä¼˜åŒ–å™¨SGDã€Momentumã€RMSPropã€Adam](https://cloud.tencent.com/developer/article/1491393)
* [æ·±åº¦å­¦ä¹ ï¼ˆä¹ï¼‰ æ·±åº¦å­¦ä¹ æœ€å…¨ä¼˜åŒ–æ–¹æ³•æ€»ç»“æ¯”è¾ƒï¼ˆSGDï¼ŒMomentumï¼ŒNesterov Momentumï¼ŒAdagradï¼ŒAdadeltaï¼ŒRMSpropï¼ŒAdamï¼‰](https://www.bbsmax.com/A/A7zgplBkJ4/)

